# Gender Bias Papers

>  Contributed by [Jishun Zhao](https://github.com/DgCtRbt) and [Shucheng Zhu](https://github.com/zhushucheng).

## Introduction

In this repo, we list some related work on gender bias. Corrections and suggestions are welcomed. 

 <img src="https://www.hh-law.com/wp-content/uploads/sites/1300396/2019/11/implicitbiasimage.jpg" width = "600" height = "400" alt="" align=center />

## Contents

1. [Volume](# Volume)
2. [Review article](##  Review article)
3. [Bias analysis](# Bias analysis)
4. [Bias measurement](# Bias measurement)
5. [Model de-bias](# Model de-bias)
6. [Text de-bias](# Text de-bias)
7. [Data set](# Data set)
8. [ArXiv's latest related papers](# ArXiv's latest related papers)
9. [COMMENT](# COMMENT )
10. [Psychology](# Psychology)
11. [Relevant literature](# Relevant literature)

## Volume

1. [Proceedings of the First Workshop on Gender Bias in Natural Language Processing](https://www.aclweb.org/anthology/W19-38.pdf)
2. [Proceedings of the Second Workshop on Gender Bias in Natural Language Processing](https://www.aclweb.org/anthology/volumes/2020.gebnlp-1/)
3. [3rd Workshop on Gender Bias in Natural Language Processing](https://genderbiasnlp.talp.cat/)

## Review article

1. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019[PDF](https://arxiv.org/abs/1906.08976v1)
2. Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview.2020.[PDF](https://arxiv.org/abs/1912.11078)


## Bias analysis

1. Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.2016.
2. Men Also Like Shopping: Reducing Gender Bias Amplification Using Corpus-level Constraints.EMNLP 2017 最佳论文. [PDF](https://arxiv.org/pdf/1707.09457.pdf)
3. Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes.2018.[PDF](https://arxiv.org/abs/1711.08412v1).[Code](https://github.com/nikhgarg/EmbeddingDynamicStereotypes)
4. Understanding the Origins of Bias in Word Embeddings.2018.[PDF](https://arxiv.org/abs/1810.03611)
5. Is there Gender bias and stereotype in Portuguese Word Embeddings? 2018.[PDF](https://arxiv.org/abs/1810.04528)
6. Learning Gender-Neutral Word Embeddings.EMNLP.2018.[PDF](https://arxiv.org/abs/1809.01496v1)
7. Measuring Societal Biases from Text Corpora with Smoothed First-Order Co-occurrence.2018.[PDF](https://arxiv.org/abs/1812.10424)
8. Measuring and Mitigating Unintended Bias in Text Classification.AAAI.2018
9. Gender Bias in Sentiment Analysis.2018.[PDF](https://wlv.openrepository.com/bitstream/handle/2436/620633/GenderBiasInSentimentAnalysisPreprint.pdf?sequence=9&isAllowed=y)
10. Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems.2018.
11. Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in Sentiment Analysis.2019.[PDF](https://arxiv.org/abs/1906.10256v2)
12. Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.03310)
13. Evaluating the Underlying Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.08783)
14. Measuring Bias in Contextualized Word Representations.2019.[PDF](https://arxiv.org/abs/1906.07337v1)
15. Examining the Presence of Gender Bias in Customer Reviews Using Word Embedding. 2019.[PDF](https://arxiv.org/abs/1902.00496v1)
16. Using Word Embeddings to Examine Gender Bias in Dutch Newspapers, 1950-1990. 2019.[PDF](https://www.aclweb.org/anthology/W19-4712/)
17. How Does Grammatical Gender Affect Noun Representations in Gender-Marking Languages? 2019. [PDF](https://arxiv.org/pdf/1910.14161.pdf)
18. Quantifying the Semantic Core of Gender Systems.EMNLP 2019 [PDF](https://arxiv.org/pdf/1910.13497.pdf)
19. Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts.2019.[PDF](https://www.aclweb.org/anthology/D19-1176/)
20. Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis.ACL.2019.[PDF](https://www.aclweb.org/anthology/W19-3803/)
21. Towards Understanding Gender Bias in Neural Relation Extraction. ACL. 2020. [PDF](https://www.aclweb.org/anthology/2020.acl-main.265/)
22. Investigating Potential Factors Associated with Gender Discrimination in Collaborative Recommender Systems.2020.[PDF](https://arxiv.org/abs/2002.07786)
23. Analyzing Gender Bias within Narrative Tropes.2020.[PDF](https://arxiv.org/pdf/2011.00092.pdf)


## Bias measurement

1. First Women, Second Sex: Gender Bias in Wikipedia. 2015
2. It's A Man's Wikipedia? Assessing Gender Inequality in An Online Encyclopedia. 2015
3. Social Bias in Elicited Natural Language Inference. 2017
4. Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts.2019
5. StereoSet: Measuring stereotypical bias in pretrained language models.2020.[PDF](https://arxiv.org/abs/2004.09456v1)
6. Measuring Individual Differences in Implicit Cognition: The Implicit Association Test. 1998.
7. National Differences in Gender–science Stereotypes Predict National Sex Differences in Science and Math Achievement.2009.
8. Semantics Derived Automatically from Language Corpora Contain Human-like Biases. 2017.
9. Assessing Social and Intersectional Biases in Contextualized Word Representations. NIPS.2019
10. Measuring Gender Bias in Word Embeddings across Domains and Discovering New Gender Bias Word Categories.2019
11. On Measuring Social Biases in Sentence Encoders.2019
12. Black Is to Criminal as Caucasian Is to Police: Detecting and Removing Multiclass Bias in Word Embeddings.2019.
13. Lipstick on A Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings but Do Not Remove Them.2019
14. Gender Bias in Neural Natural Language Processing.2018[PDF](https://arxiv.org/abs/1807.11714)
15. Reducing Gender Bias in Abusive Language Detection.2018.
16. Gender Bias in Coreference Resolution.2018
17. [Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns](https://watermark.silverchair.com/tacl_a_00240.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAqkwggKlBgkqhkiG9w0BBwagggKWMIICkgIBADCCAosGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMPE7Kg3Ht5MYve550AgEQgIICXP0XeqeYbNwTfeu-j1c7Q84pHmZAqEziDs0r7WXaeGBx5LZkRmuTp5wWdWdxFj1tqwjN3l74QyTiz7PiN066qi2gOOvAqATNT07KTu5y-R-2SPSD_ExZBGdkKDnkyGm3zIXwJ7zx7FC78Ud5b-2c5LdYNC7dyBd_4Te-ca3hwUzilZqAezF-IwBTrPTt5to0M-B10aAfHCjgxQRxui_cTtS20pDtnQEor6G9vhZwF9ckwVb47CYSqt4qoL1jDuBMTRuRiKBnr7Qp2pI6YLfRz7gtaB6plzaU_3i6tWXcO4HHPx7K3o0JbJAREUSQ3R9PAPyuUCihdQ6LtxHKRL8QEbZ5rsjSqa4_KgFDgsF7R1gycfsS1g0opxrLXQKpLrZ4ZrQTODPubSewo1Bl0jw_Yy9kKTTYCrrboEQZpwR1f7wThslo5PrykUlIwf-usJ_VP2z1ysV7wZWKQ7jYt7whsj1RNBfnn5JmwGZIOeGSvybhrfipV3qQ1LkiN1vn3XytCY9kYgohgcPyQuZWa4kAVKN5_Un32s3Ijc-7pY8y4MlA-HRfw4IZkpNpKQI2PMGThZZ2RWjJDW7z1mWvKc3-DLH_pRs56OwVTMUEYh5DoCjl57UxLgK9fhVgQGGhlpzQflDCkM-381s_j0KJV-R2aVucdagpOBNlKPriqdH3SCvvw60TEtNH9uALDxpd8AONrOXvOkW3zQvgbni-96SzWcGr6lEfVFo5g5wf8pDnMhYNVfmGEHJ476lMFdwdzaolMJ360aAGMx2s96rDmEl1EQxsSObYhfDFx1H00fo).2018.
18. Toward Gender-inclusive Coreference Resolution.2019

## Model de-bias

1. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019.[PDF](https://arxiv.org/abs/1906.08976v1)
2. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods.NAACL.2018[PDF](https://arxiv.org/abs/1804.06876v1)
3. Towards Understanding Gender Bias in Neural Relation Extraction. ACL. 2020. [PDF](https://www.aclweb.org/anthology/2020.acl-main.265/)
4. Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.03310)
5. It's All in the Name: Mitigating Gender Bias with Name-Based Counterfactual Data Substitution.2019.[PDF](https://arxiv.org/abs/1909.00871v3)
6. Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology.ACL.2019.[PDF](https://arxiv.org/abs/1906.04571)
7. Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies.2018.
8. Getting Gender Right in Neural Machine Translation.2019.[PDF](https://arxiv.org/abs/1909.05088)
9. Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem.ACL.2020.[PDF](https://arxiv.org/abs/2004.04498)
10. Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques.2019.[PDF](https://arxiv.org/abs/1901.03116)
11. Filling Gender & Number Gaps in Neural Machine Translation with Black-box Context Injection.2019.[PDF](https://arxiv.org/abs/1903.03467)
12. Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior.2018.[PDF](https://arxiv.org/abs/1802.00393)
13. Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter.
14. Examining Gender Bias in Languages with Grammatical Gender.EMNLP.2019.[PDF](https://arxiv.org/abs/1909.02224)
15. Gender-preserving Debiasing for Pre-trained Word Embeddings.2019.[PDF](https://arxiv.org/abs/1906.00742)
16. Conceptor Debiasing of Word Representations Evaluated on WEAT.2019.[PDF](https://arxiv.org/abs/1906.05993)
17. The Role of Protected Class Word Lists in Bias Identification of Contextualized Word Representations.ACL.2019.[PDF](https://www.aclweb.org/anthology/W19-3808/)
18. A Causal Inference Method for Reducing Gender Bias in Word Embedding Relations.AAAI. 2020.[PDF](https://arxiv.org/abs/1911.10787)
19. Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation.ACL.2020.[PDF](https://arxiv.org/abs/2005.00965)
20. Learning Gender-Neutral Word Embeddings.EMNLP.2018.[PDF](https://arxiv.org/abs/1809.01496v1)
21. Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function.2019.[PDF](https://arxiv.org/abs/1905.12801)
22. Mitigating Unwanted Biases with Adversarial Learning.2018.[PDF](https://arxiv.org/abs/1801.07593)
23. Resolving Gendered Ambiguous Pronouns with BERT.2019.[PDF](https://arxiv.org/abs/1906.01161)
24. Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution.2019.[PDF](https://arxiv.org/abs/1905.08868)
25. On GAP Coreference Resolution Shared Task: Insights from the 3rd Place Solution.2019.[PDF](https://www.aclweb.org/anthology/W19-3816/)
26. Transfer Learning from Pre-trained BERT for Pronoun Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3812/)
27. Gendered Pronoun Resolution Using BERT and an Extractive Question Answering Formulation.2019.[PDF](https://arxiv.org/abs/1906.03695)
28. BERT Masked Language Modeling for Co-reference Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3811/)
29. MSnet:A BERT-based Network for Gendered Pronoun Resolution.2019.[PDF](https://arxiv.org/abs/1908.00308)
30. Fill the GAP: Exploiting BERT for Pronoun Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3815/)
31. Anonymized BERT: An Augmentation Approach to the Gendered Pronoun Resolution Challenge.2019.[PDF](https://arxiv.org/abs/1905.01780)
32. Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling.2019.[PDF](https://arxiv.org/abs/1906.00839)
33. Generating Clues for Gender based Occupation De-biasing in Text.2019.[PDF](https://arxiv.org/abs/1804.03839)
34. Women, Politics and Twitter: Using Machine Learning to Change the Discourse.2019.[PDF](https://arxiv.org/abs/1911.11025)
35. Mitigating Media Bias through Neutral Article Generation.2021.[PDF](https://arxiv.org/pdf/2104.00336.pdf)
36. Mitigating Political Bias in Language Models Through Reinforced Calibration.AAAI 2021最佳论文.[PDF](https://arxiv.org/abs/2104.14795)
37. Debiasing Pre-trained Contextualised Embeddings.2021.[PDF](https://arxiv.org/abs/2101.09523)
38. The Knowref Coreference Corpus: Removing Gender and Number Cues for Difficult Pronominal Anaphora Resolution.[PDF](https://arxiv.org/abs/1811.01747)



## Text de-bias

1. Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP.2021.[PDF](https://arxiv.org/pdf/2103.00453.pdf)
2. Proposed Taxonomy for Gender Bias in Text;A Filtering Methodology for the Gender Generalization Subtype.2019.[PDF](https://www.aclweb.org/anthology/W19-3802.pdf)
3. When He Doesn’t Mean You: GenderExclusive Language as Ostracism.2011.[PDF](https://www.wgalil.ac.il/files/GENDER/gendered_language_ostracism.pdf).
4. Can Gender Fair Language Reduce Gender Stereotyping and Discrimination?.2016.[HTML](https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00025/full)
5. Multi-Dimensional Gender Bias Classification.2020.[PDF](https://arxiv.org/pdf/2005.00614.pdf)
6. Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation.[PDF](https://arxiv.org/abs/1911.03842)
7. DivGAN: Towards Diverse Paraphrase Generation via Diversified Generative Adversarial Network.[PDF](https://www.aclweb.org/anthology/2020.findings-emnlp.218/)
8. PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction.2020.[PDF](https://arxiv.org/abs/2010.13816)
9. Connotation Frames of Power and Agency in Modern Films.2017.[PDF](https://www.aclweb.org/anthology/D17-1247/)
10. Style Transfer Through Back-Translation.2018.[PDF](https://www.aclweb.org/anthology/P18-1080/)
11. Plug and Play Language Models: A Simple Approach to Controlled Text Generation.2020.[PDF](https://arxiv.org/abs/1912.02164)
12. Contextual Affective Analysis: A Case Study of People Portrayals in Online #MeToo Stories.2019.[PDF](https://arxiv.org/pdf/1904.04164.pdf)
13. Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation.2019.[PDF](https://arxiv.org/abs/1911.03842)

## Data set

1. [GeBioToolkit: Automatic Extraction of Gender-Balanced Multilingual Corpus of Wikipedia Biographies](https://xueshu.baidu.com/usercenter/paper/show?paperid=1w780m40b22108x02s2h0mt06r479606&site=xueshu_se&hitarticle=1).2020
2. Social Bias Frames: Reasoning about Social and Power Implications of Language.2020.[PDF](https://arxiv.org/abs/1911.03891)


## ArXiv's latest related papers

1. Back to Square One：Bias Detection, Training and Commonsense Disentanglement in the Winograd Schema.2021.[PDF](https://arxiv.org/abs/2104.08161)
2. Detoxifying Language Models Risks Marginalizing Minority Voices.2021.[PDF](https://arxiv.org/abs/2104.06390)
3. First the Worst：Finding Better Gender Translations during Beam Search.2021.[PDF](https://arxiv.org/abs/2104.07429)
4. Gender Bias in Machine Translation.2021.[PDF](https://arxiv.org/abs/2104.06001)
5. Improving Gender Translation Accuracy with Filtered Self-training.2021.[PDF](https://arxiv.org/abs/2104.07695)
6. Investigating Failures of Automatic Translation in the Case of Unambiguous Gender.2021.2021.[PDF](https://arxiv.org/abs/2104.07838)
7. Quantifying Gender Bias Towards Politicians in Cross-Lingual Language Models.2021.[PDF](https://arxiv.org/abs/2104.07505)
8. Unmasking the Mask - Evaluating Social Biases in Masked Language Models.2021. [PDF](https://arxiv.org/abs/2104.07496)
9. Revealing Persona Biases in Dialogue Systems.2021.[PDF](https://arxiv.org/abs/2104.08728)
10. Hidden Biases in Unreliable News Detection Datasets.2021.[PDF](https://arxiv.org/abs/2104.10130)
11. Identifying Offensive Expressions of Opinion in Context.2021.[PDF](https://arxiv.org/abs/2104.12227)
12. Contextual Lexicon-Based Approach for Hate Speech and Offensive Language Detection.2021.[PDF](https://arxiv.org/abs/2104.12265)
13. Impact of Gender Debiased Word Embeddings in Language Modeling.2021.[PDF](https://arxiv.org/abs/2105.00908)
14. The Authors Matter: Understanding and Mitigating Implicit Bias in Deep Text Classification.2021.[PDF](https://arxiv.org/abs/2105.02778)
15. Societal Biases in Language Generation: Progress and Challenges.2021.[PDF](https://arxiv.org/abs/2105.04054)
16. Evaluating Gender Bias in Natural Language Inference.2021.[PDF](https://arxiv.org/abs/2105.05541)
17. Multilingual Offensive Language Identification for Low-resource Languages.2021.[PDF](https://arxiv.org/abs/2105.05996)
18. Black or White but Never Neutral: How Readers Perceive Identity from Yellow or Skin-toned Emoji.2021.[PDF](https://arxiv.org/abs/2105.05887)
19. The Incel Lexicon: Deciphering the Emergent Cryptolect of a Global Misogynistic Community.2021.[PDF](https://arxiv.org/abs/2105.12006)
20. MBIC - A Media Bias Annotation Dataset Including Annotator Characteristics.2021.[PDF](https://arxiv.org/abs/2105.11910)
21. How to Split: The Effect of Word Segmentation on Gender Bias in Speech Translation.2021.[PDF](https://arxiv.org/abs/2105.13782)
22. A Simple Voting Mechanism for Online Sexist Content Identification.2021.[PDF](https://arxiv.org/abs/2105.14309)
23. LPF: A Language-Prior Feedback Objective Function for De-biased Visual Question Answering.2021.[PDF](https://arxiv.org/abs/2105.14300)
24. Gender Bias Amplification During Speed-Quality Optimization in Neural  Machine Translation.2021.[PDF](https://arxiv.org/abs/2106.00169)
25. Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese  Adjectives.2021.[PDF](https://arxiv.org/abs/2106.00181)
26. John Praised Mary Because He? Implicit Causality Bias and Its Interaction with Explicit Cues in LMs.2021.[PDF](https://arxiv.org/abs/2106.01060)
27. Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia.2021.[PDF](https://arxiv.org/abs/2106.01601)
28. Understanding and Countering Stereotypes: A Computational Approach to  the Stereotype Content Model.2021.[PDF](https://arxiv.org/abs/2106.02596)
29. Towards Equal Gender Representation in the Annotations of Toxic Language  Detection.2021.[PDF](https://arxiv.org/abs/2106.02183)
30. A Diachronic Evaluation of Gender Asymmetry in Euphemism.2021.[PDF](https://arxiv.org/abs/2106.02083)
31. LGBTQ-AI? Exploring Expressions of Gender and Sexual Orientation in Chatbots.2021.[PDF](https://arxiv.org/abs/2106.02076)

## COMMENT 

1. Menegatti M, Rubini M. Gender Bias and Sexism in Language[M]//Oxford Research Encyclopedia of Communication. 2017. [PDF](https://oxfordre.com/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-470)
2. James Z, Londa S.  AI Can Be Sexist and Racist—It’s Time to Make It Fair[J]. Nature, 2018. [PDF](https://www.nature.com/articles/d41586-018-05707-8)

## Psychology

1. [偏见、歧视与刻板印象，有什么不一样？高浩容](https://www.jianshu.com/p/b5c6465a9b73)
2. [Implicit Bias: What It Means and How It Affects Behavior](https://www.thoughtco.com/understanding-implicit-bias-4165634).

## Relevant literature

1. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.[PDF](https://jmlr.org/papers/v21/20-074.html)
